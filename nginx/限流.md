nginx 自带的限流是按照漏桶算法来的。

所谓漏桶算法是指，服务器处理请求时，会将请求放置在一个队列中，然后一点点将请求取出来进行处理；如果队列满了，则剩下的请求会被直接废弃。

漏桶算法的优点是，面对请求的突然暴增时，依然可以控制请求的处理速率，不至于过载太大；但是缺点就是请求需要排队。

相对应的，令牌桶算法则不需要排队，服务端会定时往桶中放置令牌，在处理请求时，会先尝试去拿令牌，如果有就处理，没有的话，可以直接废弃请求，也有的实现中会设置排队等待；令牌桶的方案中，请求可以不排队，服务端新建一条请求后，只要拿到令牌，立马就进行处理；缺点则是负载可能会忽高忽低。



### 配置

nginx 配置限流的指令是两个：

- limit_req_zone;
- limit_req



#### limit_req_zone

通常在 http 块中定义，需要三个参数：

1. key，定义应用限制的请求特性，一般是 remote_addr， 表示按照客户端 ip 进行区分；
2. zone，定义存储上面 key 的位置以及总的共享存储区域大小，要知道这个区域是可以在各 worker 进程之间共享的；
3. rate，定义最大请求速率，表示每秒不能超过的请求数；不过 nginx 是按照毫秒为精度来控制的。

以下是一个示例：

```shell
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;
```

上面的意思是：按照客户端 ip 进行区分限制，建立一个叫做 mylimit 的共享内存，用来存储 ip ，总大小为 10m；每个 ip 对应的请求，每秒处理数不超过 10  个，进一步说是指每 100 毫秒处理 1 个。

#### limit_req

limit_req_zone 只是限制共享内存区域的参数，不限制请求速率。需要再通过 limit_req 参数配合，这个命令用在 location 或者 server 块中。

```shell
location /login/ {
    limit_req zone=mylimit burst=20 nodelay;

    proxy_pass http://my_upstream;
}
```

上面是一个示例，其中 burst 表示最多存储 20 个请求，多余的将直接返回  503，缓存的请求将每隔一定时间（根据 zone 的设置）被处理后释放空位置。如果设置 nodelay，则会提高响应。



#### nodelay 参数的一些说明

nodelay 参数需要配合 limit_req 一起使用。

这个参数主要区别在于对空闲位置的处理。比如速率设置为1/s，burst=5,然后来了10个请求。

在不设置 nodelay 的情况下，会有5个请求放置在队列中，抛弃4个；然后nginx会每隔一秒处理一条，大概在6秒左右处理完毕；可以实测以下；

而在设置 nodelay 的情况下，同样会有5个请求放置在队列中，抛弃4个；但是nginx会迅速将这5个请求进行处理，如果 worker 进程足够多的话，几乎是瞬间完成；但要注意的是，虽然这些请求几乎同时被处理完毕了，但是空闲位置的释放，依然是100毫秒一个，这就维持了 rate 的一致。所以 nodelay 主要是用来处理瞬时请求，至于请求上限，是没有变化的。



除了限制请求速率，也能限制连接数。

#### limit_conn_zone

类似于前面，不过它是用来限制连接数的，与  limit_conn 配合使用：

```shell
limit_conn_zone $binary_remote_addr zone=perip:10m;
    limit_conn_zone $server_name zone=perserver:10m;
    server {
        ...
        limit_conn perip 10;
        limit_conn perserver 100;
    }
```

整体类似前面，这里是指按照客户端 ip 限制，每个 ip 最多持有10个连接；同时虚拟主机最多持有 100 个连接。要注意的是，请求头被后端处理后，连接才计数。



#### 黑白名单限制

除了上面的两种方式，即限制请求数和限制连接数，也可以设置白名单；这样白名单中的请求可以不受限制的访问，具体参数可以搜索 geo map 等。



#### 限制传输速度 

除了限制请求，在响应时，也可以设置限制数据传输速率，通过 limit_rate_after 和 limit_rate 限制。